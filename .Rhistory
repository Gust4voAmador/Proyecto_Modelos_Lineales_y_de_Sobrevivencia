resid.raw <- resid(LC.lm)      # Los residuales crudos
resid.std <- rstandard(LC.lm)    # Los residuales estandarizados
c(Raw = var(resid.raw), Standardized = var(resid.std))
resid.raw <- resid(LC.lm)      # Los residuales crudos
resid.std <- rstandard(LC.lm)    # Los residuales estandarizados
c(Raw = var(resid.raw), Standardized = var(resid.std))
print("Notar que lo que se muestra es la variación de los residuos de cada observación")
hatvalues(fit)
h <- hatvalues(LC.lm)       # LC.lm es el modelo ajustado
sort(h, decreasing = TRUE)[1:2]  # Los dos apalancamientos más altos
# 2.4 Los Apalancamientos en Modelos de Regresión Lineal
```{r}
h <- hatvalues(LC.lm)       # LC.lm es el modelo ajustado
sort(h, decreasing = TRUE)[1:2]  # Los dos apalancamientos más altos
library(GLMsData); data(lungcap)
lungcap$Smoke <- factor(lungcap$Smoke, levels = c(0, 1),labels = c("Non-smoker", "Smoker"))
LC.lm <- lm(FEV ~ Ht + Gender + Smoke, data = lungcap)
resid.raw <- resid(LC.lm)      # Los residuales crudos
resid.std <- rstandard(LC.lm)    # Los residuales estandarizados
c(Raw = var(resid.raw), Standardized = var(resid.std))
print("Notar que lo que se muestra es la variación de los residuos de cada observación")
h <- hatvalues(LC.lm)       # LC.lm es el modelo ajustado
sort(h, decreasing = TRUE)[1:2]  # Los dos apalancamientos más altos
# Graficar residuales estandarizados contra la variable 'Ht'
scatter.smooth(rstandard(LC.lm) ~ lungcap$Ht, col="grey",
las=1, ylab="Standardized residuals", xlab="Height (inches)")
# Calcular residuales parciales y graficarlos para la variable 'Ht'
partial.resid <- resid(LC.lm, type="partial")
termplot(LC.lm, partial.resid=TRUE, terms="Ht", las=1)
# Graficar residuales estandarizados contra los valores ajustados
scatter.smooth(rstandard(LC.lm) ~ fitted(LC.lm), col="grey",
las=1, ylab="Standardized residuals", xlab="Fitted values")
# Crear el gráfico Q-Q de los residuales estandarizados
qqnorm(rstandard(LC.lm), las=1, pch=19)
qqline(rstandard(LC.lm))  # Agregar línea de referencia
# Crear un lag plot de residuales estandarizados
r <- rstandard(LC.lm)
plot(r[-length(r)], r[-1], xlab="Residual at time t-1", ylab="Residual at time t",
main="Lag Plot", pch=19, col="blue")
#rstudent(LC.lm)
summary(cbind(Standardized = rstandard(LC.lm),
Studentized = rstudent(LC.lm)))
# Calcular la distancia de Cook
cook_vals <- cooks.distance(LC.lm)
# Crear el gráfico con eje X en el orden de las observaciones
plot(cook_vals,
type = "h",              # barras verticales
xlab = "Observación",
ylab = "Distancia de Cook",
main = "Gráfico de la Distancia de Cook")
# Opcional: agregar un umbral de referencia, como 4/n
abline(h = 4/length(cook_vals), col = "red", lty = 2)
LC.im <- influence.measures(LC.lm)
names(LC.im)
cd.max <- which.max(cooks.distance(LC.lm))
cd.min <- which.min(cooks.distance(LC.lm))
c(Min.Cook = cd.min, Max.Cook = cd.max)
out <- cbind(DFFITS = dffits(LC.lm),
Cooks.distance = cooks.distance(LC.lm),
Cov.ratio = covratio(LC.lm))
round(out[c(cd.min, cd.max), ], 5)
# Gráfico de Cook's Distance
plot(cooks.distance(LC.lm), type="h",
main="Cook's distance", ylab="D", xlab="Observation number", las=1)
# Gráfico de DFFITS
plot(dffits(LC.lm), type="h",
main="DFFITS", ylab="DFFITS", xlab="Observation number", las=1)
# Gráfico de DFBETAS para el coeficiente beta correspondiente a la variable 'Ht'
plot(dfbetas(LC.lm)[, 3], type="h",
main="DFBETAS para beta2", ylab="DFBETAS", xlab="Observation number", las=1)
LC.sqrt <- update(LC.lm, sqrt(FEV) ~ .) #se está transformando la variable y (FEV) con
scatter.smooth(rstandard(LC.sqrt) ~ fitted(LC.sqrt), las=1, col="grey",
ylab="Standardized residuals", xlab="Fitted values",
main="Square-root transformation")
LC.log <- update(LC.lm, log(FEV) ~ .)
scatter.smooth(rstandard(LC.log) ~ fitted(LC.log), las=1, col="grey",
ylab="Standardized residuals", xlab="Fitted values",
main="Log transformation")
library(MASS)
boxcox(FEV ~ Ht + Gender + Smoke, lambda=seq(-0.25, 0.25, length=11), data=lungcap)
data(windmill); names(windmill)
scatter.smooth(windmill$DC ~ windmill$Wind, main="No transforms",
xlab="Wind speed", ylab="DC output", las=1)
wm.m1 <- lm(DC ~ Wind, data=windmill)
scatter.smooth(rstandard(wm.m1) ~ fitted(wm.m1), main="No transforms",xlab="Standardized residuals", ylab="Fitted values", las=1)
scatter.smooth(windmill$DC ~ log(windmill$Wind), main="Log(Wind)", xlab="log(Wind speed)", ylab="DC output", las=1)
wm.m2 <- lm(DC ~ log(Wind), data=windmill)
scatter.smooth(rstandard(wm.m2) ~ fitted(wm.m2), main="Log(Wind)", ylab="Standardized residuals", xlab="Fitted values", las=1)
scatter.smooth(windmill$DC ~ (1/windmill$Wind), main="1/Wind", xlab="1/(Wind speed)", ylab="DC output", las=1)
wm.m3 <- lm(DC ~ I(1/Wind), data=windmill)
scatter.smooth(rstandard(wm.m3) ~ fitted(wm.m3), main="1/Wind", ylab="Standardized residuals", xlab="Fitted values", las=1)
LC.lm.log <- lm(log(FEV) ~ log(Ht), data=lungcap)
printCoefmat(coef(summary(LC.lm.log)))
plot(log(FEV) ~ log(Ht), data=lungcap, las=1)
data(nhospital); names(nhospital)
cor(nhospital)
printCoefmat(coef(summary(nh.m1)))
nh.m1 <- lm(MainHours ~ Eligible + OpRooms + Cases, data = nhospital)
printCoefmat(coef(summary(nh.m1)))
library(GLMsData)
data(quilpie); names(quilpie)
mu <- c(0.2, 0.4, 0.5, 0.6, 0.8)  # Valores candidatos para mu
ll <- rep(0, 5)                 # Vector para guardar los log-verosimilitudes
for (i in 1:5){
ll[i] <- sum(dbinom(quilpie$y, size=1, prob=mu[i], log=TRUE))
}
data.frame(Mu = mu, LogLikelihood = ll)
# Generar una secuencia de valores candidatos para mu (por ejemplo, de 0.1 a 0.9)
mu_vals <- seq(0.1, 0.9, length.out = 200)
# Calcular la función de log-verosimilitud para cada valor de mu
ll_vals <- sapply(mu_vals, function(mu) sum(dbinom(quilpie$y, size = 1, prob = mu, log = TRUE)))
# Convertir el log-verosimilitud a verosimilitud (exponenciando)
likelihood_vals <- exp(ll_vals)
# Graficar la función de verosimilitud y el log-verosimilitud en paneles separados
par(mfrow = c(2, 1), mar = c(4, 4, 2, 1))  # Configurar dos paneles verticales
# Panel superior: Gráfico de la función de verosimilitud
plot(mu_vals, likelihood_vals, type = "l", lwd = 2, col = "blue",
xlab = expression(mu), ylab = "Verosimilitud",
main = "Función de Verosimilitud")
abline(v = 0.5147, lty = 2, col = "red")  # Línea vertical en el MLE
# Panel inferior: Gráfico de la función log-verosimilitud
plot(mu_vals, ll_vals, type = "l", lwd = 2, col = "blue",
xlab = expression(mu), ylab = "Log-Verosimilitud",
main = "Función Log-Verosimilitud")
abline(v = 0.5147, lty = 2, col = "red")  # Línea vertical en el MLE```
# Restablecer la distribución de los gráficos a una sola figura (opcional)
par(mfrow = c(1, 1))
n <- length(quilpie$y)
muhat <- mean(quilpie$y)
Info <- n / (muhat * (1 - muhat))
c(muhat = muhat, FisherInfo = Info)
1/sqrt(Info)
## --- datos -------------------------------------------------------------
## Se supone que ya existe el data‑frame `quilpie`
## con la variable binaria y (1 = lluvia > 10 mm; 0 = lo contrario)
y  <- quilpie$y                # vector de 0/1
n  <- length(y)                # tamaño muestral
## --- estimación de máxima verosimilitud -------------------------------
muhat <- mean(y)               # MLE de µ en el modelo Bernoulli
var_hat <- muhat*(1 - muhat)/n # varianza asintótica de mû
## --- estadístico de Wald ----------------------------------------------
W <- (muhat - 0.5)^2 / var_hat
pW <- pchisq(W, df = 1, lower.tail = FALSE)
## --- estadístico de score ---------------------------------------------
U_mu0  <- (sum(y)/0.5)-((n-sum(y))/0.5)           # U(mu0)
I_mu0  <- n / (0.5 * (1 - 0.5))                   # I(mu0)
S  <- U_mu0^2 / I_mu0                         # S = U^2/I
pS <- pchisq(S, df = 1, lower.tail = FALSE)
## --- estadístico de razón de verosimilitud ----------------------------
logLik_mu0   <- sum(dbinom(y, size = 1, prob = 0.5, log = TRUE))
logLik_muhat <- sum(dbinom(y, size = 1, prob = muhat, log = TRUE))
L <- 2 * (logLik_muhat - logLik_mu0)
pL <- pchisq(L, df = 1, lower.tail = FALSE)
## --- resumen ----------------------------------------------------------
round(
cbind(
Estadístico = c(W, S, L),
"p‑valor"    = c(pW, pS, pL)
),
4
)
y   <- quilpie$y                          # 0 / 1  (lluvia > 10 mm)
x   <- quilpie$SOI                        # covariable – Southern Oscillation
n   <- length(y)
X   <- cbind(1, x)                        # matriz de diseño completa (β0, β1)
## ----------------------------------------------------------------------
## 2.  Modelo completo (β0, β1 libres)  y modelo nulo (β0 = β1 = 0)
## ----------------------------------------------------------------------
fit.full <- glm(y ~ x, family = binomial(link = "logit"))
beta_hat <- coef(fit.full)                # (β̂0, β̂1)
## log‑likelihood del modelo completo  (la función ‘logLik’ lo entrega)
ll_full  <- as.numeric(logLik(fit.full))
## log‑likelihood bajo H0  (μ = 0.5 constante  ⇒ logit(μ) = 0)
ll_null  <- sum(dbinom(y, size = 1, prob = 0.5, log = TRUE))
## ----------------------------------------------------------------------
## 3.  Estadístico Wald
##     W  = (β̂  - β0)ᵀ  (Var β̂)⁻¹  (β̂  - β0)     con β0 = (0,0)
## ----------------------------------------------------------------------
V     <- vcov(fit.full)                   # Var‑Cov de β̂ ( = I(β̂)⁻¹ )
Wald  <- t(beta_hat) %*% solve(V) %*% beta_hat
p.W   <- pchisq(Wald, df = 2, lower.tail = FALSE)
## ----------------------------------------------------------------------
## 4.  Estadístico Score (Rao)
##     S  = U(β0)ᵀ  I(β0)⁻¹  U(β0)
##       donde  U(β0) = Xᵀ (y - μ0)          con μ0 = 0.5
##              I(β0) = Xᵀ W X,  W = μ0 (1-μ0) I
## ----------------------------------------------------------------------
mu0   <- 0.5
U0    <- t(X) %*% (y - mu0)               # vector score bajo la nula
Wmat  <- diag(mu0 * (1 - mu0), n)         # 0.25 * I
I0    <- t(X) %*% Wmat %*% X
Score <- t(U0) %*% solve(I0) %*% U0
p.S   <- pchisq(Score, df = 2, lower.tail = FALSE)
## ----------------------------------------------------------------------
## 5.  Cociente de verosimilitudes
##     L  = 2 [ ℓ(β̂)  –  ℓ(β0) ]
## ----------------------------------------------------------------------
L.Ratio <- 2 * (ll_full - ll_null)
p.L     <- pchisq(L.Ratio, df = 2, lower.tail = FALSE)
## ----------------------------------------------------------------------
## 6.  Resumen
## ----------------------------------------------------------------------
out <- rbind(
Wald            = c(stat = Wald,     p.value = p.W),
Score           = c(stat = Score,    p.value = p.S),
L.Ratio         = c(stat = L.Ratio,  p.value = p.L)
)
print( round(out, 4) )
library(GLMsData)
data(nminer)
# Definimos puntos de corte y asignamos las observaciones a grupos
breaks   <- c(-Inf, 4, 11, 15, 19, Inf) + 0.5
Eucs.cut <- cut(nminer$Eucs, breaks)
# Estadísticos por grupo
mn <- tapply(nminer$Minerab, Eucs.cut, mean)     # medias
vr <- tapply(nminer$Minerab, Eucs.cut, var)      # varianzas
sz <- tapply(nminer$Minerab, Eucs.cut, length)   # tamaños
cbind("Tamaño" = sz, "Media" = mn, "Varianza" = vr)
plot(log(vr) ~ log(mn),
pch  = 19,
las  = 1,
cex  = 0.45*sqrt(sz),        # el área refleja el tamaño muestral
xlab = "Log de las medias",
ylab = "Log de las varianzas")
hm.lm <- lm(log(vr) ~ log(mn), weights = sz)     # ajuste ponderado
abline(hm.lm, lty = 2)                           # recta estimada
glm(y ~ x, family = binomial(link = "logit"), data = datos)
library(GLMsData)
data(nminer)
# Definimos puntos de corte y asignamos las observaciones a grupos
breaks   <- c(-Inf, 4, 11, 15, 19, Inf) + 0.5
Eucs.cut <- cut(nminer$Eucs, breaks)
# Estadísticos por grupo
mn <- tapply(nminer$Minerab, Eucs.cut, mean)     # medias
vr <- tapply(nminer$Minerab, Eucs.cut, var)      # varianzas
sz <- tapply(nminer$Minerab, Eucs.cut, length)   # tamaños
cbind("Tamaño" = sz, "Media" = mn, "Varianza" = vr)
plot(log(vr) ~ log(mn),
pch  = 19,
las  = 1,
cex  = 0.45*sqrt(sz),        # el área refleja el tamaño muestral
xlab = "Log de las medias",
ylab = "Log de las varianzas")
hm.lm <- lm(log(vr) ~ log(mn), weights = sz)     # ajuste ponderado
abline(hm.lm, lty = 2)                           # recta estimada
glm(y ~ x, family = binomial(link = "logit"), data = datos)
library(GLMsData); data(nminer)
nm.m1 <- glm(Minerab ~ Eucs,
data = nminer,
family = poisson(link = "log"),
control = list(trace = TRUE))   # Muestra la deviancia en cada iteración
nm.m1
# Distribuciones de probabilidad de X1, X2, X3, X4
f1 <- c(0.6, 0.0, 0.3, 0.0, 0.1)  # Pr(X1 = 0,1,2,3,4)
f2 <- c(0.7, 0.2, 0.1, 0.0, 0.0)  # Pr(X2 = 0,1,2,3,4)
f3 <- c(0.6, 0.0, 0.0, 0.4, 0.0)  # Pr(X3 = 0,1,2,3,4)
f4 <- c(0.9, 0.0, 0.0, 0.0, 0.1)  # Pr(X4 = 0,1,2,3,4)
# Función para convolucionar dos vectores de probabilidad discretos
convolucion <- function(p, q) {
len <- length(p) + length(q) - 1
result <- rep(0, len)
for (i in 1:length(p)) {
for (j in 1:length(q)) {
result[i + j - 1] <- result[i + j - 1] + p[i] * q[j]
}
}
return(result)
}
# Aplicar convoluciones sucesivas
f12 <- convolucion(f1, f2)
f123 <- convolucion(f12, f3)
f1234 <- convolucion(f123, f4)
# Mostrar resultado
resultado <- data.frame(x = 0:(length(f1234)-1), `P(S = x)` = round(f1234, 6))
print(resultado)
setwd("C:/Users/AMADOR/OneDrive - Universidad de Costa Rica/I-2025/Modelos lineales y de sobrevivencia/Proyecto Modelos")
library(readr)
aata_raw <- read_csv("Dengue diseases dataset.csv")
View(data_raw)
library(readr)
data_raw <- read_csv("Dengue diseases dataset.csv")
View(data_raw)
data_raw.info()
# Ver estructura general
str(data_raw)
summary(data_raw)
# Ver si hay datos faltantes
colSums(is.na(data_raw))
# Ver nombres de variables
names(data_raw)
# Ver estructura general
str(data_raw)
#summary(data_raw)
# Ver si hay datos faltantes
colSums(is.na(data_raw))
# Ver nombres de variables
names(data_raw)
print(describe(Age))
describe(data_raw)
library(skimr)
library(skimr)
skim(data_raw$Age)
attributes(data_raw$Age)
data_raw$`Differential Count` <- factor(data_raw$`Differential Count`,
levels = c(0, 1),
labels = c("No", "Yes"))
data_raw$`RBC PANEL` <- factor(data_raw$`RBC PANEL`,
levels = c(0, 1),
labels = c("No", "Yes"))
data_raw$`Final Output` <- factor(data_raw$`Final Output`,
levels = c(0, 1),
labels = c("Negative", "Positive"))
data_raw$`Differential Count` <- factor(data_raw$`Differential Count`,
levels = c(0, 1),
labels = c("No", "Yes"))
data_raw$`RBC PANEL` <- factor(data_raw$`RBC PANEL`,
levels = c(0, 1),
labels = c("No", "Yes"))
data_raw$`Final Output` <- factor(data_raw$`Final Output`,
levels = c(0, 1),
labels = c("Negative", "Positive"))
View(data_raw)
library(readr)
data_raw <- read_csv("Dengue diseases dataset.csv")
View(data_raw)
library(readr)
data_raw <- read_csv("Dengue diseases dataset.csv")
View(data_raw)
data_raw$`Differential Count` <- factor(data_raw$`Differential Count`,
levels = c(0, 1),
labels = c("No", "Yes"))
data_raw$`RBC PANEL` <- factor(data_raw$`RBC PANEL`,
levels = c(0, 1),
labels = c("No", "Yes"))
data_raw$`Final Output` <- factor(data_raw$`Final Output`,
levels = c(0, 1),
labels = c("Negative", "Positive"))
View(data_raw)
# Histograma
hist(data_raw$Age, main = "Distribución de la edad", xlab = "Edad", col = "skyblue")
hist(data_raw$Haemoglobin, main = "Distribución de la edad", xlab = "Edad", col = "skyblue")
hist(data_raw$`WBC Count`, main = "Distribución de la edad", xlab = "Edad", col = "skyblue")
hist(data_raw$`Platelet Count`, main = "Distribución de la edad", xlab = "Edad", col = "skyblue")
hist(data_raw$PDW, main = "Distribución de la edad", xlab = "Edad", col = "skyblue")
# Boxplot
#boxplot(data_raw$Haemoglobin, main = "Distribución del ingreso", ylab = "Ingreso mensual")
# Estadísticas básicas
#mean(datos$ingreso, na.rm = TRUE)
#sd(datos$ingreso, na.rm = TRUE)
# Histograma
hist(data_raw$Age, main = "Distribución de la edad", xlab = "Edad", col = "skyblue")
hist(data_raw$Haemoglobin, main = "Distribución de la Haemoglobin", xlab = "Haemoglobin", col = "skyblue")
hist(data_raw$`WBC Count`, main = "Distribución de la WBC Count", xlab = "WBC Count", col = "skyblue")
hist(data_raw$`Platelet Count`, main = "Distribución de la Platelet Count", xlab = "Platelet Count", col = "skyblue")
hist(data_raw$PDW, main = "Distribución de la PDW", xlab = "PDW", col = "skyblue")
# Boxplot
#boxplot(data_raw$Haemoglobin, main = "Distribución del ingreso", ylab = "Ingreso mensual")
# Estadísticas básicas
#mean(datos$ingreso, na.rm = TRUE)
#sd(datos$ingreso, na.rm = TRUE)
# Boxplot
boxplot(data_raw$Age, main = "Boxplot de la Edad",
ylab = "Edad",
col = "lightgreen",
horizontal = TRUE)
boxplot(data_raw$Haemoglobin,
main = "Boxplot de la Haemoglobina",
ylab = "Haemoglobina",
col = "lightgreen",
horizontal = TRUE)
boxplot(data_raw$`WBC Count`,
main = "Boxplot de la WBC Count",
ylab = "WBC Count",
col = "lightgreen",
horizontal = TRUE)
boxplot(data_raw$`Platelet Count`,
main = "Boxplot de la Platelet Count",
ylab = "Platelet Count",
col = "lightgreen",
horizontal = TRUE)
boxplot(data_raw$PDW,
main = "Boxplot de la PDW",
ylab = "PDW",
col = "lightgreen",
horizontal = TRUE)
# Frecuencias
table(data_raw$Sex)
# Gráfico de barras
barplot(table(data_raw$Sex), col = "lightgreen", main = "Distribución del nivel educativo")
# Gráfico de barras para Differential Count
barplot(table(data_raw$`Differential Count`),
col = "lightblue",
main = "Distribución de Differential Count",
ylab = "Frecuencia")
# Gráfico de barras para RBC PANEL
barplot(table(data_raw$`RBC PANEL`),
col = "lightcoral",
main = "Distribución de RBC PANEL",
ylab = "Frecuencia")
# Gráfico de barras para Final Output
barplot(table(data_raw$`Final Output`),
col = "lightgoldenrod",
main = "Distribución de Final Output",
ylab = "Frecuencia")
table(data_raw$Sex)
barplot(table(data_raw$Sex), col = "lightgreen", main = "Distribución del nivel educativo")
barplot(table(data_raw$`Differential Count`),
col = "lightblue",
main = "Distribución de Differential Count",
ylab = "Frecuencia")
barplot(table(data_raw$`RBC PANEL`),
col = "lightcoral",
main = "Distribución de RBC PANEL",
ylab = "Frecuencia")
barplot(table(data_raw$`Final Output`),
col = "lightgoldenrod",
main = "Distribución de Final Output",
ylab = "Frecuencia")
#table(data_raw$Sex)
barplot(table(data_raw$Sex), col = "lightgreen", main = "Distribución del nivel educativo")
barplot(table(data_raw$`Differential Count`),
col = "lightblue",
main = "Distribución de Differential Count",
ylab = "Frecuencia")
barplot(table(data_raw$`RBC PANEL`),
col = "lightcoral",
main = "Distribución de RBC PANEL",
ylab = "Frecuencia")
barplot(table(data_raw$`Final Output`),
col = "lightgoldenrod",
main = "Distribución de Final Output",
ylab = "Frecuencia")
# Gráfico de dispersión entre variables continuas
plot(data_raw$Age, data_raw$Haemoglobin,
main = "Edad vs Haemoglobina",
xlab = "Edad", ylab = "Haemoglobina",
col = "steelblue", pch = 16)
plot(data_raw$`WBC Count`, data_raw$`Platelet Count`,
main = "WBC Count vs Platelet Count",
xlab = "WBC Count", ylab = "Platelet Count",
col = "tomato", pch = 16)
# Correlaciones
cor(data_raw$Age, data_raw$Haemoglobin, use = "complete.obs")
cor(data_raw$`WBC Count`, data_raw$`Platelet Count`, use = "complete.obs")
numeric_vars <- data_raw[, c("Age", "Haemoglobin", "WBC Count", "Platelet Count", "PDW")]
cor(numeric_vars, use = "complete.obs")
library(corrplot)
numeric_vars <- data_raw[, c("Age", "Haemoglobin", "WBC Count", "Platelet Count", "PDW")]
# Matriz de correlación
cor_matrix <- cor(numeric_vars, use = "complete.obs")
# Gráfico
corrplot(cor_matrix, method = "color", type = "upper",
tl.col = "black", tl.srt = 45,
addCoef.col = "black", # muestra los coeficientes
col = colorRampPalette(c("red", "white", "blue"))(200))
# Gráfico de dispersión entre variables continuas
plot(data_raw$Age, data_raw$Haemoglobin,
main = "Edad vs Haemoglobina",
xlab = "Edad", ylab = "Haemoglobina",
col = "steelblue", pch = 16)
plot(data_raw$`WBC Count`, data_raw$`Platelet Count`,
main = "WBC Count vs Platelet Count",
xlab = "WBC Count", ylab = "Platelet Count",
col = "tomato", pch = 16)
plot(data_raw$PDW, data_raw$`Platelet Count`,
main = "WBC Count vs Platelet Count",
xlab = "WBC Count", ylab = "Platelet Count",
col = "purple", pch = 16)
# Correlaciones
cor(data_raw$Age, data_raw$Haemoglobin, use = "complete.obs")
cor(data_raw$`WBC Count`, data_raw$`Platelet Count`, use = "complete.obs")
# Boxplot de Haemoglobina según sexo
boxplot(Haemoglobin ~ Sex, data = data_raw,
main = "Haemoglobina según Sexo",
col = c("skyblue", "salmon"),
ylab = "Haemoglobina")
# Boxplot de WBC Count según resultado final
boxplot(`WBC Count` ~ `Final Output`, data = data_raw,
main = "WBC Count según Final Output",
col = c("lightgreen", "gold"),
ylab = "WBC Count")
# Boxplot de PDW según Differential Count
boxplot(PDW ~ `Differential Count`, data = data_raw,
main = "PDW según Differential Count",
col = c("pink", "lightblue"),
ylab = "PDW")
# Tabla de contingencia
tabla_dc_final <- table(data_raw$`Differential Count`, data_raw$`Final Output`)
print(tabla_dc_final)
# Barras agrupadas
barplot(tabla_dc_final,
beside = TRUE,
col = c("lightblue", "lightpink"),
legend = TRUE,
main = "Final Output según Differential Count",
ylab = "Frecuencia")
# Otra tabla: Sex vs Final Output
tabla_sex_final <- table(data_raw$Sex, data_raw$`Final Output`)
barplot(tabla_sex_final,
beside = TRUE,
col = c("lightcyan", "lightcoral"),
legend = TRUE,
main = "Final Output según Sexo")
library(corrplot)
numeric_vars <- data_raw[, c("Age", "Haemoglobin", "WBC Count", "Platelet Count", "PDW")]
# Matriz de correlación
cor_matrix <- cor(numeric_vars, use = "complete.obs")
# Gráfico
corrplot(cor_matrix, method = "color", type = "upper",
tl.col = "black", tl.srt = 45,
addCoef.col = "black", # muestra los coeficientes
col = colorRampPalette(c("red", "white", "blue"))(200))
