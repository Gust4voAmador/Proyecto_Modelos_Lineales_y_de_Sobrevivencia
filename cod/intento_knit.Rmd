---
title: "Untitled"
author: "Gustavo Amador Fonseca C20451"
date: "2025-07-07"
output: html_document
---

```{r, echo = FALSE, warning= FALSE, results='hide', message = FALSE}
library(readr)
library(dplyr)
library(ggplot2)
library(ggcorrplot)
library(dplyr)
library(stats)
library(pROC)
library(caret)
library(ggplot2)
library(boot)
library(scorecard)

data_raw <- read_csv("../data/Dengue diseases dataset.csv", show_col_types = FALSE)

```

# 1. Limpieza de datos

# Limpieza de Datos

```{r}
#Creación de copia del df original (crudo)
datos <- data_raw
names(datos)[9] <- "Dengue Diagnosis"
# Asegurar que Dengue sea binaria
datos$`Dengue Diagnosis` <- as.numeric(as.character(datos$`Dengue Diagnosis`))
#View(datos)
```

Se están eliminando las observaciones con datos faltantes
```{r}

# Filtrar observaciones con datos completos en todas las variables potenciales del scope
datos <- datos %>%
  select(`Dengue Diagnosis`, Age, Haemoglobin, PDW, `WBC Count`, 
         `Differential Count`, `RBC PANEL`, `Platelet Count` ) %>%
  na.omit()
datos
```

# 2. Ajuste de modelo con varibles crudas (sin transformaciones)

## Conjunto de variables con Platelet Count

### Validación cruzada cláisca con 5 pliegues

Primeramente una validación cruzada simple y clásico de cinco pliegues para evaluar la capacidad predictiva del modelo logistico final.

```{r, warning=FALSE}
set.seed(187)

# Crear la variable de clase en el dataset correcto
datos$DengueFactor <- factor(
  ifelse(datos$`Dengue Diagnosis` == 1, "Sí", "No"),
  levels = c("No", "Sí")
)

# Eliminar NAs si existen en las columnas relevantes
datos_filtrado <- datos %>%
  select(DengueFactor, `Platelet Count`) %>%
  na.omit()

# Control para validación cruzada
ctrl <- trainControl(
  method = "cv",           
  number = 5,              
  classProbs = TRUE,       
  summaryFunction = twoClassSummary,
  savePredictions = "final"
)

# Entrenar el modelo con Platelet Count (sin WoE)
modelo_cv_clasico_plat <- train(
  DengueFactor ~ `Platelet Count`,
  data = datos_filtrado,
  method = "glm",
  metric = "ROC",          
  trControl = ctrl
)

print(modelo_cv_clasico_plat)

# AUC promedio en 5 folds
mean(modelo_cv_clasico_plat$resample$ROC)


```

La validación cruzada clásica de 5 pliegues utilizando únicamente la variable Platelet Count mostró un excelente desempeño predictivo. El modelo alcanzó un AUC promedio de 0.9945, con una sensibilidad de 98.67% y una especificidad de 98.58%, lo cual indica una alta capacidad para distinguir correctamente entre pacientes con y sin diagnóstico de dengue usando solo esta variable hematológica.

### Validación cruzada estratificada sin balanceo

```{r, warning=FALSE, message=FALSE}

set.seed(187)

# Crear variable binaria
datos$DengueFactor <- factor(
  ifelse(datos$`Dengue Diagnosis` == 1, "Sí", "No"),
  levels = c("No", "Sí")
)

# Filtrar columnas necesarias y eliminar NA
datos_filtrado <- datos %>%
  select(DengueFactor, `Platelet Count`) %>%
  na.omit()

# Proporciones del conjunto de entrenamiento
train_props <- c(0.7, 0.5, 0.3, 0.1)
reps <- 10

# Control de validación cruzada
ctrl <- trainControl(
  method = "cv",
  number = 5,
  classProbs = TRUE
)

# Guardar resultados
resultados_estratificados <- data.frame()

for (p in train_props) {
  for (i in 1:reps) {
    idx_train <- createDataPartition(datos_filtrado$DengueFactor, p = p, list = FALSE)
    datos_train <- datos_filtrado[idx_train, ]
    datos_test <- datos_filtrado[-idx_train, ]
    
    modelo <- train(
      DengueFactor ~ `Platelet Count`,
      data = datos_train,
      method = "glm",
      trControl = ctrl,
      metric = "ROC"
    )
    
    pred_test <- predict(modelo, newdata = datos_test, type = "prob")
    
    auc_test <- roc(response = datos_test$DengueFactor,
                    predictor = pred_test$Sí,
                    levels = c("No", "Sí"))$auc
    
    resultados_estratificados <- rbind(resultados_estratificados,
      data.frame(
        TamanoEntrenamiento = round(p * 100),
        Repeticion = i,
        AUC_Test = auc_test
      )
    )
  }
}

# Ver resultados
print(resultados_estratificados)
resumen_estratificados <- aggregate(AUC_Test ~ TamanoEntrenamiento, data = resultados_estratificados, FUN = mean)
print(resumen_estratificados)
```

La validación cruzada estratificada sin balanceo, realizada con diferentes proporciones del conjunto de entrenamiento (10%, 30%, 50% y 70%), mostró que el modelo logístico basado únicamente en Platelet Count mantiene un desempeño predictivo sobresaliente en todos los escenarios. Los valores promedio de AUC oscilaron entre 0.9932 y 0.9959, alcanzando su mejor rendimiento con un 70% del conjunto dedicado al entrenamiento. Esto indica que incluso con tamaños de muestra relativamente pequeños, el modelo logra discriminar eficazmente entre casos positivos y negativos de dengue.


### Validación cruzada repetida con Platelet Count (30% training)

```{r, warning=FALSE, , message=FALSE}


set.seed(187)

# Definir variable binaria en el dataset correcto
datos$DengueFactor <- factor(
  ifelse(datos$`Dengue Diagnosis` == 1, "Sí", "No"),
  levels = c("No", "Sí")
)

# Filtrar columnas necesarias y eliminar NA
datos_filtrado <- datos %>%
  select(DengueFactor, `Platelet Count`) %>%
  na.omit()

# Repeticiones
reps <- 100
porcentaje_entrenamiento <- 0.3

# Inicializar almacenamiento
metricas <- data.frame()

for (i in 1:reps) {
  # Partición estratificada (30% para entrenamiento)
  idx_train <- createDataPartition(datos_filtrado$DengueFactor, p = porcentaje_entrenamiento, list = FALSE)
  train_data <- datos_filtrado[idx_train, ]
  test_data <- datos_filtrado[-idx_train, ]
  
  # Control de CV estratificada
  ctrl <- trainControl(
    method = "cv",
    number = 5,
    classProbs = TRUE,
    summaryFunction = twoClassSummary,
    savePredictions = "final"
  )
  
  # Ajuste de modelo logístico
  modelo <- train(
    DengueFactor ~ `Platelet Count`,
    data = train_data,
    method = "glm",
    metric = "ROC",
    trControl = ctrl
  )
  
  # Predicción en conjunto de prueba
  pred_probs <- predict(modelo, newdata = test_data, type = "prob")
  pred_clase <- predict(modelo, newdata = test_data)
  
  # Calcular AUC y métricas
  auc <- roc(response = test_data$DengueFactor,
             predictor = pred_probs$Sí,
             levels = c("No", "Sí"))$auc
  
  cm <- confusionMatrix(pred_clase, test_data$DengueFactor, positive = "Sí")
  
  metricas <- rbind(metricas, data.frame(
    Repeticion = i,
    AUC = auc,
    Accuracy = cm$overall["Accuracy"],
    Sensibilidad = cm$byClass["Sensitivity"],
    Especificidad = cm$byClass["Specificity"],
    F1 = cm$byClass["F1"],
    Precision = cm$byClass["Precision"]
  ))
}

# Mostrar resumen de métricas
summary(metricas)
```

La validación cruzada repetida, realizada con 100 iteraciones utilizando solo el 30% del conjunto de datos para entrenamiento y Platelet Count como única variable predictora, evidenció un rendimiento predictivo excepcional. El modelo obtuvo un AUC promedio de 0.9938, con una exactitud media de 98.70%, sensibilidad de 98.88% y especificidad de 98.32%. Además, las métricas F1 y precisión fueron igualmente altas, lo que confirma la estabilidad y efectividad del modelo, incluso con una proporción limitada de datos para el aprendizaje. Estos resultados respaldan la capacidad de Platelet Count para discriminar adecuadamente entre pacientes con y sin diagnóstico de dengue.


## Conjunto de variables con WBC Count

### Validación cruzada cláisca con 5 pliegues

```{r, warning=FALSE}
set.seed(187)

# Crear la variable de clase como factor binario
datos$DengueFactor <- factor(
  ifelse(datos$`Dengue Diagnosis` == 1, "Sí", "No"),
  levels = c("No", "Sí")
)

# Filtrar columnas necesarias y eliminar NA
datos_filtrado <- datos %>%
  select(DengueFactor, `WBC Count`) %>%
  na.omit()

# Control para validación cruzada
ctrl <- trainControl(
  method = "cv",           
  number = 5,              
  classProbs = TRUE,       
  summaryFunction = twoClassSummary,
  savePredictions = "final"
)

# Entrenar el modelo con WBC Count como predictor
modelo_cv_clasico_wbc <- train(
  DengueFactor ~ `WBC Count`,
  data = datos_filtrado,
  method = "glm",
  metric = "ROC",          
  trControl = ctrl
)

# Imprimir resultados
print(modelo_cv_clasico_wbc)

# AUC promedio en los 5 folds
mean(modelo_cv_clasico_wbc$resample$ROC)
```

### Validación cruzada estratificada sin balanceo WBC Count

```{r, warning=FALSE, message=FALSE}

set.seed(187)

# Crear variable binaria
datos$DengueFactor <- factor(
  ifelse(datos$`Dengue Diagnosis` == 1, "Sí", "No"),
  levels = c("No", "Sí")
)

# Filtrar columnas necesarias y eliminar NA
datos_filtrado <- datos %>%
  select(DengueFactor, `WBC Count`) %>%
  na.omit()

# Proporciones del conjunto de entrenamiento
train_props <- c(0.7, 0.5, 0.3, 0.1)
reps <- 10

# Control de validación cruzada
ctrl <- trainControl(
  method = "cv",
  number = 5,
  classProbs = TRUE
)

# Guardar resultados
resultados_estratificados <- data.frame()

for (p in train_props) {
  for (i in 1:reps) {
    idx_train <- createDataPartition(datos_filtrado$DengueFactor, p = p, list = FALSE)
    datos_train <- datos_filtrado[idx_train, ]
    datos_test <- datos_filtrado[-idx_train, ]
    
    modelo <- train(
      DengueFactor ~ `WBC Count`,
      data = datos_train,
      method = "glm",
      trControl = ctrl,
      metric = "ROC"
    )
    
    pred_test <- predict(modelo, newdata = datos_test, type = "prob")
    
    auc_test <- roc(response = datos_test$DengueFactor,
                    predictor = pred_test$Sí,
                    levels = c("No", "Sí"))$auc
    
    resultados_estratificados <- rbind(resultados_estratificados,
      data.frame(
        TamanoEntrenamiento = round(p * 100),
        Repeticion = i,
        AUC_Test = auc_test
      )
    )
  }
}

# Ver resultados
print(resultados_estratificados)
resumen_estratificados <- aggregate(AUC_Test ~ TamanoEntrenamiento, data = resultados_estratificados, FUN = mean)
print(resumen_estratificados)
```

### Validación cruzada repetida con WBC Count (30% training)

```{r, warning=FALSE, , message=FALSE}
set.seed(187)

# Definir variable binaria
datos$DengueFactor <- factor(
  ifelse(datos$`Dengue Diagnosis` == 1, "Sí", "No"),
  levels = c("No", "Sí")
)

# Filtrar columnas necesarias y eliminar NA
datos_filtrado <- datos %>%
  select(DengueFactor, `WBC Count`) %>%
  na.omit()

# Repeticiones
reps <- 100
porcentaje_entrenamiento <- 0.3

# Inicializar almacenamiento
metricas <- data.frame()

for (i in 1:reps) {
  # Partición estratificada (30% para entrenamiento)
  idx_train <- createDataPartition(datos_filtrado$DengueFactor, p = porcentaje_entrenamiento, list = FALSE)
  train_data <- datos_filtrado[idx_train, ]
  test_data <- datos_filtrado[-idx_train, ]
  
  # Control de CV estratificada
  ctrl <- trainControl(
    method = "cv",
    number = 5,
    classProbs = TRUE,
    summaryFunction = twoClassSummary,
    savePredictions = "final"
  )
  
  # Ajuste del modelo
  modelo <- train(
    DengueFactor ~ `WBC Count`,
    data = train_data,
    method = "glm",
    metric = "ROC",
    trControl = ctrl
  )
  
  # Predicción
  pred_probs <- predict(modelo, newdata = test_data, type = "prob")
  pred_clase <- predict(modelo, newdata = test_data)
  
  # AUC
  auc <- roc(response = test_data$DengueFactor,
             predictor = pred_probs[,"Sí"],
             levels = c("No", "Sí"))$auc
  
  # Matriz de confusión y métricas
  cm <- confusionMatrix(pred_clase, test_data$DengueFactor, positive = "Sí")
  
  metricas <- rbind(metricas, data.frame(
    Repeticion = i,
    AUC = auc,
    Accuracy = cm$overall["Accuracy"],
    Sensibilidad = cm$byClass["Sensitivity"],
    Especificidad = cm$byClass["Specificity"],
    F1 = cm$byClass["F1"],
    Precision = cm$byClass["Precision"]
  ))
}

# Ver resumen
summary(metricas)
```


# 3. Transformación WoE

```{r, message=FALSE}
datos_woe <- read_csv("C:/Users/AMADOR/OneDrive - Universidad de Costa Rica/I-2025/Modelos lineales y de sobrevivencia/Proyecto Modelos/data/datos_woe.csv")
```

```{r}
datos_woe
#View(datos_woe)
```

La WBC Count_woe fue colapsada en un solo bin: [-Inf, Inf], esto lo que puede significar es que el algoritmo no encontró forma de dividirla en grupos útiles, seguro porque presenta una correlación lineal con Dengue altísima (0.92)... por lo que no se va a considerar la forma woe en la regresión.

## Explorar ajuste del modelo logistico con todas las variables

```{r, warning=FALSE}
# Asegurar que las variables categóricas están como factores
datos_woe$`Differential Count` <- as.factor(datos_woe$`Differential Count`)
datos_woe$`RBC PANEL` <- as.factor(datos_woe$`RBC PANEL`)

# Modelo logístico con todas las variables (originales + transformadas)
modelo_logit_completo <- glm(`Dengue Diagnosis` ~ 
                         Age + Age_woe +
                         Haemoglobin + Haemoglobin_woe +
                         `Platelet Count` + `Platelet Count_woe` +
                         PDW + PDW_woe +
                         `WBC Count` + 
                         `Differential Count` + 
                         `RBC PANEL`,
                       data = datos_woe,
                       family = binomial)

# Ver el resumen del modelo
summary(modelo_logit_completo)

```

Se puede ver que ni la varible Platelet Count se ve estadísticamente importante... por loque quitaré WBC Count que es con la que presenta mayor colinealidad con Platelet y Dengue

Metira: ahora dejaré a WBC Counto porque fue la que presentó menor BIC, al contrario de Platelet count


### Selección de variables a partir del modelo completo con BIC

Considera las variablaes del ajuste logístico anterior y hace la selección BIC para escogencia de variables

```{r, results='markup', echo=TRUE, message=FALSE, warning=FALSE}

# Filtrar filas completas (sin NA en variables relevantes)
variables_modelo <- c("Dengue Diagnosis", 
                      "Age", "Age_woe", "Haemoglobin", 
                      "Platelet Count", "Platelet Count_woe", 
                      "PDW", "Differential Count", "RBC PANEL")

datos_modelo <- datos_woe[complete.cases(datos_woe[, variables_modelo]), ]

# Ajustar el modelo (recordar que no considera los NA)
modelo_logit_sin_woe <- glm(`Dengue Diagnosis` ~ 
                              Age + Age_woe + Haemoglobin + 
                              `Platelet Count` + `Platelet Count_woe` + `WBC Count`+ 
                              PDW + `Differential Count` + `RBC PANEL`,
                            data = datos_modelo,
                            family = binomial)

# Selección con BIC
modelo_step_bic <- step(modelo_logit_sin_woe, direction = "both", k = log(nrow(datos_modelo)))


summary(modelo_step_bic)

```
Se puede ver que llegó a las variables más importantes... pero estas al estar tan correlacionadas no muestran una significancia
estadísticamente considerable, lo que dificulta la interpretación de sus coeficientes y del moedelo en genera, por lo que se descarta
a pesar de tener un AIC bajo.


## Segundo ajuste eliminando variables

### Con variable Platelet Count y Platelet Count_woe

```{r}
# Ahora quitando las variables woe con valor p de 1, excepto edad_woe
modelo_logit_sin_woe <- glm(`Dengue Diagnosis` ~ 
                         Age + Age_woe +
                         Haemoglobin +
                         `Platelet Count` + `Platelet Count_woe` +
                         PDW +
                         #`WBC Count` + 
                         `Differential Count` + 
                         `RBC PANEL`,
                       data = datos_woe,
                       family = binomial)
summary(modelo_logit_sin_woe)
```
En este ajuste se puede ver que ya la variable Platelet Count_woe se muestra altamente significativa, mientras que la otra varieable con con la que Dengue Diagnosis tenía alta colinealidad no se muestra poco significativa en comparación, entonces se decide continuar con las variables Platelet Count y Platelet Count_woe, ahora es necesario hacer selección de variables


### Con variable WBC Count

```{r}
# Ahora quitando las variables woe con valor p de 1, excepto edad_woe
modelo_logit_sin_woe <- glm(`Dengue Diagnosis` ~ 
                         Age + Age_woe +
                         Haemoglobin +
                        #`Platelet Count` + `Platelet Count_woe` +
                         PDW +
                         `WBC Count` + 
                         `Differential Count` + 
                         `RBC PANEL`,
                       data = datos_woe,
                       family = binomial)
summary(modelo_logit_sin_woe)
```
Tiene un mejor ajuste global penalizado, pero solo una variable significativa marginalmente.

Preferí modelo con variables significativas, como el A, aunque el BIC sea mayor. Así ase interpreta mejor el efecto de cada variable.


### Selección de variables anteriores con BIC

Considera las variablaes del ajuste logístico anterior y hace la selección BIC para escogencia de variables

```{r, results='markup', echo=TRUE, message=FALSE, warning=FALSE}

# Filtrar filas completas (sin NA en variables relevantes)
variables_modelo <- c("Dengue Diagnosis", 
                      "Age", "Age_woe", "Haemoglobin", 
                      "Platelet Count", "Platelet Count_woe", 
                      "PDW", "Differential Count", "RBC PANEL")

datos_modelo <- datos_woe[complete.cases(datos_woe[, variables_modelo]), ]

# Ajustar el modelo (recordar que no considera los NA)
modelo_logit_sin_woe <- glm(`Dengue Diagnosis` ~ 
                              Age + Age_woe + Haemoglobin + 
                              `Platelet Count` + `Platelet Count_woe` + 
                              PDW + `Differential Count` + `RBC PANEL`,
                            data = datos_modelo,
                            family = binomial)

# Selección con BIC
modelo_step_bic <- step(modelo_logit_sin_woe, direction = "both", k = log(nrow(datos_modelo)))


summary(modelo_step_bic)

```


En el modelo ajustado se observa que tanto Platelet Count como su transformación Platelet Count_woe resultan estadísticamente significativas. Sin embargo, dado que ambas variables capturan esencialmente la misma información, ya que una es directamente y la otra mediante codificación WoE, es razonable suponer que existe una alta colinealidad entre ellas.

La inclusión simultánea de estas dos variables podría generar redundancia en el modelo y dificultar la interpretación de los coeficientes. Además, podría afectar negativamente la estabilidad del modelo y su capacidad predictiva si se traslada a nuevos datos. Por ello, es mejor eliminar la variable Platelet Count, dado que la variable Platelet Count_woe ofrece una mejor representación con la variable respuesta.

# 4. Modelo logístico final y resumen

Se considera como modelo logistico final el que solo utiliza la variables predictoras de Age_woe y Platelet Count_woe

```{r}
model_logit_final <- glm(formula = `Dengue Diagnosis` ~ Age_woe + 
    `Platelet Count_woe`, family = binomial, data = datos_modelo)

summary(model_logit_final)
```


# Ver la capacidad predictiva

## Ver capacidad predictiva con variables transformadas

### Validación cruzada cláisca con 5 pliegues

Primeramente una validación cruzada simple y clásico de cinco pliegues para evaluar la capacidad predictiva del modelo logistico final.

```{r, warning=FALSE}
set.seed(187)
library(caret)
library(pROC)

# la variable debe respuesta es un factor con clase positiva definida
datos_modelo$DengueFactor <- factor(
  ifelse(datos_modelo$`Dengue Diagnosis` == 1, "Sí", "No"),
  levels = c("No", "Sí")
)

# Control de validación cruzada clásica (5 folds)
ctrl <- trainControl(
  method = "cv",           
  number = 5,              
  classProbs = TRUE,       
  summaryFunction = twoClassSummary,
  savePredictions = "final"
)

# Entrenar modelo 
modelo_cv_clasico <- train(
  DengueFactor ~ Age_woe + `Platelet Count_woe`,
  data = datos_modelo,
  method = "glm",
  metric = "ROC",          
  trControl = ctrl
)

print(modelo_cv_clasico)

# Promedio de AUC en los 5 folds
mean(modelo_cv_clasico$resample$ROC)

```

La validación cruzada de 5 pliegues del modelo logístico final mostró un excelente desempeño predictivo, con un AUC promedio de 0.9922. El modelo identifica correctamente el 97.7% de los casos positivos (sensibilidad) y clasifica adecuadamente el 99.5% de los casos negativos (especificidad), lo que indica una alta capacidad de discriminación y confiabilidad para predecir el diagnóstico de dengue.

### CV estratifada sin balanceo

```{r cv-estratificada, message=FALSE, warning=FALSE}

set.seed(187)

# Asegurar niveles correctos (No = 0, Sí = 1)
datos_modelo$DengueFactor <- factor(
  ifelse(datos_modelo$`Dengue Diagnosis` == 1, "Sí", "No"),
  levels = c("No", "Sí")
)

# Conjuntos de entrenamiento
train_props <- c(0.7, 0.5, 0.3, 0.1)

# Repeticiones por proporción de conjunto de training
reps <- 10

# validación cruzada
ctrl <- trainControl(
  method = "cv",
  number = 5,
  classProbs = TRUE
)

# Inicializar para guardar resultados
resultados_estratificados <- data.frame()

for (p in train_props) {
  for (i in 1:reps) {
    # Partición estratificada (sin balanceo)
    idx_train <- createDataPartition(datos_modelo$DengueFactor, p = p, list = FALSE)
    datos_train <- datos_modelo[idx_train, ]
    datos_test <- datos_modelo[-idx_train, ]
    
    # Entrenar el modelo directamente sobre el conjunto estratificado (no balanceado)
    modelo <- train(
      DengueFactor ~ Age_woe + `Platelet Count_woe`,
      data = datos_train,
      method = "glm",
      trControl = ctrl,
      metric = "ROC"
    )
    
    # Predicciones en conjunto de prueba
    pred_test <- predict(modelo, newdata = datos_test, type = "prob")
    
    # Calcular AUC en test
    auc_test <- roc(response = datos_test$DengueFactor,
                    predictor = pred_test$Sí,
                    levels = c("No", "Sí"))$auc

    # Guardar resultado
    resultados_estratificados <- rbind(resultados_estratificados,
                                       data.frame(TamanoEntrenamiento = round(p * 100),
                                                  Repeticion = i,
                                                  AUC_Test = auc_test))
  }
}


```

```{r}
# Ver resultados
print(resultados_estratificados)
resumen_estratificados <- aggregate(AUC_Test ~ TamanoEntrenamiento, data = resultados_estratificados, FUN = mean)
print(resumen_estratificados)

```

Se evaluó el modelo logístico utilizando validación cruzada estratificada con diferentes tamaños de conjunto de entrenamiento (10%, 30%, 50% y 70%), repitiendo el proceso 10 veces por proporción. Los resultados muestran una alta estabilidad y capacidad predictiva del modelo, con valores promedio de AUC superiores a 0.99 en todos los casos. El mejor desempeño se obtuvo con el 50% de los datos de entrenamiento (AUC promedio = 0.9945), lo que confirma que incluso con muestras relativamente pequeñas, el modelo logra distinguir eficazmente entre casos positivos y negativos de dengue.

## Balanceo artificial de las clases con upSample

```{r resultados-balanceados, message=FALSE, warning=FALSE}

set.seed(187)

# Asegurar niveles correctos: "No" (sin dengue), "Sí" (con dengue)
datos_modelo$DengueFactor <- factor(
  ifelse(datos_modelo$`Dengue Diagnosis` == 1, "Sí", "No"),
  levels = c("No", "Sí")
)

train_props <- c(0.7, 0.5, 0.3, 0.1)

reps <- 10

# Control validación cruzada
ctrl <- trainControl(
  method = "cv",
  number = 5,
  classProbs = TRUE,
  summaryFunction = twoClassSummary,
  savePredictions = "final"
)

# Inicializar 
resultados_balanceados <- data.frame()

for (p in train_props) {
  for (i in 1:reps) {
    
    # Estratificación del conjunto de entrenamiento
    idx_train <- createDataPartition(datos_modelo$DengueFactor, p = p, list = FALSE)
    datos_train <- datos_modelo[idx_train, ]
    datos_test <- datos_modelo[-idx_train, ]
    
    # Balancear clases en el conjunto de entrenamiento con upSample()
    datos_train_balanceado <- upSample(
      x = datos_train[, c("Age_woe", "Platelet Count_woe")],
      y = datos_train$DengueFactor,
      yname = "DengueFactor"
    )
    
    # Entrenar modelo logístico
    modelo <- train(
      DengueFactor ~ Age_woe + `Platelet Count_woe`,
      data = datos_train_balanceado,
      method = "glm",
      trControl = ctrl,
      metric = "ROC"
    )
    
    # Predicción sobre conjunto de prueba (no balanceado)
    pred_test <- predict(modelo, newdata = datos_test, type = "prob")
    
    # Calcular AUC
    auc_test <- roc(response = datos_test$DengueFactor,
                    predictor = pred_test$Sí,
                    levels = c("No", "Sí"))$auc

    # Guardar resultados
    resultados_balanceados <- rbind(resultados_balanceados,
                        data.frame(TamanoEntrenamiento = round(p * 100),
                                   Repeticion = i,
                                   AUC_Test = auc_test))
  }
}


```

```{r}
# Mostrar tablas resultados
print(resultados_balanceados)
resumen_balanceados <- aggregate(AUC_Test ~ TamanoEntrenamiento, data = resultados_balanceados, FUN = mean)
print(resumen_balanceados)
```

El balanceo artificial mediante sobremuestreo no mejora significativamente el desempeño del modelo. En algunos casos incluso reduce ligeramente el AUC. Esto se debe a que las variables transformadas (Age_woe y Platelet Count_woe) ya ajustan tan bien al modelo que los cambios en el tamaño de entrenamiento o el balanceo no generan diferencias sustanciales en la capacidad predictiva.

Considerar que: El sobremuestreo (overfitting) puede hacer que algunas observaciones se repitan mucho.

# Validación cruzada repetida (30% de trainig)

```{r, warning=FALSE, message=FALSE}
set.seed(187)

# Variable de clase como factor binario
datos_modelo$DengueFactor <- factor(
  ifelse(datos_modelo$`Dengue Diagnosis` == 1, "Sí", "No"),
  levels = c("No", "Sí")
)

# Repeticiones de la validación
reps <- 100
porcentaje_entrenamiento <- 0.3

# Almacenar resultados
metricas <- data.frame()

for (i in 1:reps) {
  
  #Partición estratificada (30% para training)
  idx_train <- createDataPartition(datos_modelo$DengueFactor, p = porcentaje_entrenamiento, list = FALSE)
  train_data <- datos_modelo[idx_train, ]
  test_data <- datos_modelo[-idx_train, ]
  
  #Control de validación cruzada estratificada
  ctrl <- trainControl(
    method = "cv",
    number = 5,
    classProbs = TRUE,
    summaryFunction = twoClassSummary,
    savePredictions = "final"
  )
  
  # Ajuste de modelo
  modelo <- train(
    DengueFactor ~ Age_woe + `Platelet Count_woe`,
    data = train_data,
    method = "glm",
    metric = "ROC",
    trControl = ctrl
  )
  
  #Predicción sobre test externo
  pred_probs <- predict(modelo, newdata = test_data, type = "prob")
  pred_clase <- predict(modelo, newdata = test_data)
  
  #AUC
  auc <- roc(response = test_data$DengueFactor,
             predictor = pred_probs$Sí,
             levels = c("No", "Sí"))$auc
  
  #Matriz de confusión y métricas
  cm <- confusionMatrix(pred_clase, test_data$DengueFactor, positive = "Sí")
  
  metricas <- rbind(metricas, data.frame(
    Repeticion = i,
    AUC = auc,
    Accuracy = cm$overall["Accuracy"],
    Sensibilidad = cm$byClass["Sensitivity"],
    Especificidad = cm$byClass["Specificity"],
    F1 = cm$byClass["F1"],
    Precision = cm$byClass["Precision"]
  ))
}

# Ver resumen
print(summary(metricas))

```

El modelo logístico validado con 100 repeticiones usando solo el 30% de los datos para entrenamiento mantiene un rendimiento sobresaliente. Se obtuvo un AUC promedio de 0.9929, con exactitud media del 98.96%, sensibilidad del 99.51% y especificidad del 97.80%.

Este desempeño se debe a que las variables transformadas Age_woe y Platelet Count_woe reflejan de forma muy clara el diagnóstico de dengue. Más que mejorar el modelo, los cambios en técnicas de muestreo o balanceo tienen poco efecto, porque estas variables ya capturan de manera directa y efectiva la señal del fenómeno.


