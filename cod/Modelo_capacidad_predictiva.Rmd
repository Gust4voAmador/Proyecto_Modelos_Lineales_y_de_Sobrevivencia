---
title: "Logistico"
author: "Gustavo Amador Fonseca C20451"
date: "2025-06-16"
output:
  html_document: default
  pdf_document: default
---

```{r, echo = FALSE, warning= FALSE, results='hide', message = FALSE}
library(readr)
library(dplyr)
library(ggplot2)
library(ggcorrplot)
library(dplyr)
library(stats)
library(pROC)
library(caret)
library(ggplot2)
library(boot)
library(scorecard)

data_raw <- read_csv("../data/Dengue diseases dataset.csv", show_col_types = FALSE)

```

# 1. Limpieza de datos

# Limpieza de Datos

```{r}
#Creación de copia del df original (crudo)
datos <- data_raw
names(datos)[9] <- "Dengue Diagnosis"
# Asegurar que Dengue sea binaria
datos$`Dengue Diagnosis` <- as.numeric(as.character(datos$`Dengue Diagnosis`))
#View(data_clean)
```

```{r}


# Eliminar la observaciones nulas en Dengue Diagnosis
datos <- datos[!is.na(datos$`Dengue Diagnosis`),]
datos
```

# 2. Ajuste de modelo con varibles crudas (sin transformaciones)

Como se hizo en el otro .Rmd de modelo logístico

# 3. Transformación WoE

```{r}
# Variables continuas para transformar con WoE
vars_continuas <- c("Age", "Haemoglobin", "Platelet Count", "PDW", "WBC Count")

# Crear los bins WoE
bins <- woebin(dt = datos, y = "Dengue Diagnosis", x = vars_continuas)

# Aplicar WoE a una copia 
woe_transformado <- woebin_ply(dt = datos, bins = bins)

# Extraer solo columnas _woe
woe_solo <- select(woe_transformado, ends_with("_woe"))

# Unir sin perder 
datos_woe <- bind_cols(datos, woe_solo)
```

```{r}
datos_woe
#View(datos_woe)
```

La WBC Count_woe fue colapsada en un solo bin: [-Inf, Inf], esto lo que puede significar es que el algoritmo no encontró forma de dividirla en grupos útiles, seguro porque presenta una correlación lineal con Dengue altísima (0.92)... por lo que no se va a considerar la forma woe en la regresión.

```{r}
print(sum(datos$`Dengue Diagnosis` == 1))
print(sum(datos$`Dengue Diagnosis` == 0))
```

## Explorar ajuste del modelo logistico con todas las variables

```{r}
# Asegurar que las variables categóricas están como factores
datos_woe$Sex <- as.factor(datos_woe$Sex)
datos_woe$`Differential Count` <- as.factor(datos_woe$`Differential Count`)
datos_woe$`RBC PANEL` <- as.factor(datos_woe$`RBC PANEL`)

# Modelo logístico con todas las variables (originales + transformadas)
modelo_logit_completo <- glm(`Dengue Diagnosis` ~ 
                         Age + Age_woe +
                         Haemoglobin + Haemoglobin_woe +
                         `Platelet Count` + `Platelet Count_woe` +
                         PDW + PDW_woe +
                         `WBC Count` + 
                         Sex + 
                         `Differential Count` + 
                         `RBC PANEL`,
                       data = datos_woe,
                       family = binomial)

# Ver el resumen del modelo
summary(modelo_logit_completo)

```

Se puede ver que ni la varible Platelet Count se ve estadísticamente importante... por loque quitaré WBC Count que es con la que presenta mayor colinealidad con Platelet y Dengue

## Segundo ajuste eliminando variables

### Con variable Platelet Count y Platelet Count_woe

```{r}
# Ahora quitando las variables woe con valor p de 1, excepto edad_woe
modelo_logit_sin_woe <- glm(`Dengue Diagnosis` ~ 
                         Age + Age_woe +
                         Haemoglobin +
                         `Platelet Count` + `Platelet Count_woe` +
                         PDW +
                         #`WBC Count` + 
                         `Differential Count` + 
                         `RBC PANEL`,
                       data = datos_woe,
                       family = binomial)
summary(modelo_logit_sin_woe)
```

### Con variable WBC Count

```{r}
# Ahora quitando las variables woe con valor p de 1, excepto edad_woe
modelo_logit_sin_woe <- glm(`Dengue Diagnosis` ~ 
                         Age + Age_woe +
                         Haemoglobin +
                        #`Platelet Count` + `Platelet Count_woe` +
                         PDW +
                         `WBC Count` + 
                         `Differential Count` + 
                         `RBC PANEL`,
                       data = datos_woe,
                       family = binomial)
summary(modelo_logit_sin_woe)
```

En este ajuste se puede ver que ya la variable Platelet Count_woe se muestra altamente significativa, mientras que la otra varieable con con la que Dengue Diagnosis tenía alta colinealidad no se muestra poco significativa en comparación, entonces se decide continuar con las variables Platelet Count y Platelet Count_woe, ahora es necesario hacer selección de variables

### Selección de variables anteriores con BIC

Considera las variablaes del ajuste logístico anterior y hace la selección BIC para escogencia de variables

```{r, results='markup', echo=TRUE, message=FALSE, warning=FALSE}

# Filtrar filas completas (sin NA en variables relevantes)
variables_modelo <- c("Dengue Diagnosis", 
                      "Age", "Age_woe", "Haemoglobin", 
                      "Platelet Count", "Platelet Count_woe", 
                      "PDW", "Differential Count", "RBC PANEL")

datos_modelo <- datos_woe[complete.cases(datos_woe[, variables_modelo]), ]

# Ajustar el modelo (recordar que no considera los NA)
modelo_logit_sin_woe <- glm(`Dengue Diagnosis` ~ 
                              Age + Age_woe + Haemoglobin + 
                              `Platelet Count` + `Platelet Count_woe` + 
                              PDW + `Differential Count` + `RBC PANEL`,
                            data = datos_modelo,
                            family = binomial)

# Selección con BIC
modelo_step_bic <- step(modelo_logit_sin_woe, direction = "both", k = log(nrow(datos_modelo)))


summary(modelo_step_bic)

```

En el modelo ajustado se observa que tanto Platelet Count como su transformación Platelet Count_woe resultan estadísticamente significativas. Sin embargo, dado que ambas variables capturan esencialmente la misma información, ya que una es directamente y la otra mediante codificación WoE, es razonable suponer que existe una alta colinealidad entre ellas.

La inclusión simultánea de estas dos variables podría generar redundancia en el modelo y dificultar la interpretación de los coeficientes. Además, podría afectar negativamente la estabilidad del modelo y su capacidad predictiva si se traslada a nuevos datos. Por ello, es mejor eliminar la variable Platelet Count, dado que la variable Platelet Count_woe ofrece una mejor representación con la variable respuesta.

# 4. Modelo logístico final y resumen

Se considera como modelo logistico final el que solo utiliza la variables predictoras de Age_woe y Platelet Count_woe

```{r}
model_logit_final <- glm(formula = `Dengue Diagnosis` ~ Age_woe + 
    `Platelet Count_woe`, family = binomial, data = datos_modelo)

summary(model_logit_final)
```

# Ver la capacidad predictiva

## Ver capacidad predictiva con variables no ajustadas (con platelet count y WBC Count)

Ver con solo platelet counto y con WBC count la capacidad predictiva de las variables no transformadas.

## Ver capacidad predictiva con variables transformadas

### Validación cruzada cláisca con 5 pliegues

Primeramente una validación cruzada simple y clásico de cinco pliegues para evaluar la capacidad predictiva del modelo logistico final.

```{r, warning=FALSE}
set.seed(187)

# la variable debe respuesta es un factor con clase positiva definida
datos_modelo$DengueFactor <- factor(
  ifelse(datos_modelo$`Dengue Diagnosis` == 1, "Sí", "No"),
  levels = c("No", "Sí")
)

# Control de validación cruzada clásica (5 folds)
ctrl <- trainControl(
  method = "cv",           
  number = 5,              
  classProbs = TRUE,       
  summaryFunction = twoClassSummary,
  savePredictions = "final"
)

# Entrenar modelo 
modelo_cv_clasico <- train(
  DengueFactor ~ Age_woe + `Platelet Count_woe`,
  data = datos_modelo,
  method = "glm",
  metric = "ROC",          
  trControl = ctrl
)

print(modelo_cv_clasico)

# Promedio de AUC en los 5 folds
mean(modelo_cv_clasico$resample$ROC)

```

La validación cruzada de 5 pliegues del modelo logístico final mostró un excelente desempeño predictivo, con un AUC promedio de 0.9922. El modelo identifica correctamente el 97.7% de los casos positivos (sensibilidad) y clasifica adecuadamente el 99.5% de los casos negativos (especificidad), lo que indica una alta capacidad de discriminación y confiabilidad para predecir el diagnóstico de dengue.

### CV estratifada sin balanceo

```{r cv-estratificada, message=FALSE, warning=FALSE}

set.seed(187)

# Asegurar niveles correctos (No = 0, Sí = 1)
datos_modelo$DengueFactor <- factor(
  ifelse(datos_modelo$`Dengue Diagnosis` == 1, "Sí", "No"),
  levels = c("No", "Sí")
)

# Conjuntos de entrenamiento
train_props <- c(0.7, 0.5, 0.3, 0.1)

# Repeticiones por proporción de conjunto de training
reps <- 10

# validación cruzada
ctrl <- trainControl(
  method = "cv",
  number = 5,
  classProbs = TRUE
)

# Inicializar para guardar resultados
resultados_estratificados <- data.frame()

for (p in train_props) {
  for (i in 1:reps) {
    # Partición estratificada (sin balanceo)
    idx_train <- createDataPartition(datos_modelo$DengueFactor, p = p, list = FALSE)
    datos_train <- datos_modelo[idx_train, ]
    datos_test <- datos_modelo[-idx_train, ]
    
    # Entrenar el modelo directamente sobre el conjunto estratificado (no balanceado)
    modelo <- train(
      DengueFactor ~ Age_woe + `Platelet Count_woe`,
      data = datos_train,
      method = "glm",
      trControl = ctrl,
      metric = "ROC"
    )
    
    # Predicciones en conjunto de prueba
    pred_test <- predict(modelo, newdata = datos_test, type = "prob")
    
    # Calcular AUC en test
    auc_test <- roc(response = datos_test$DengueFactor,
                    predictor = pred_test$Sí,
                    levels = c("No", "Sí"))$auc

    # Guardar resultado
    resultados_estratificados <- rbind(resultados_estratificados,
                                       data.frame(TamanoEntrenamiento = round(p * 100),
                                                  Repeticion = i,
                                                  AUC_Test = auc_test))
  }
}


```

```{r}
# Ver resultados
print(resultados_estratificados)
resumen_estratificados <- aggregate(AUC_Test ~ TamanoEntrenamiento, data = resultados_estratificados, FUN = mean)
print(resumen_estratificados)

```

Se evaluó el modelo logístico utilizando validación cruzada estratificada con diferentes tamaños de conjunto de entrenamiento (10%, 30%, 50% y 70%), repitiendo el proceso 10 veces por proporción. Los resultados muestran una alta estabilidad y capacidad predictiva del modelo, con valores promedio de AUC superiores a 0.99 en todos los casos. El mejor desempeño se obtuvo con el 50% de los datos de entrenamiento (AUC promedio = 0.9945), lo que confirma que incluso con muestras relativamente pequeñas, el modelo logra distinguir eficazmente entre casos positivos y negativos de dengue.

## Balanceo artificial de las clases con upSample

```{r cv-estratificada, message=FALSE, warning=FALSE}

set.seed(187)

# Asegurar niveles correctos: "No" (sin dengue), "Sí" (con dengue)
datos_modelo$DengueFactor <- factor(
  ifelse(datos_modelo$`Dengue Diagnosis` == 1, "Sí", "No"),
  levels = c("No", "Sí")
)

train_props <- c(0.7, 0.5, 0.3, 0.1)

reps <- 10

# Control validación cruzada
ctrl <- trainControl(
  method = "cv",
  number = 5,
  classProbs = TRUE,
  summaryFunction = twoClassSummary,
  savePredictions = "final"
)

# Inicializar 
resultados_balanceados <- data.frame()

for (p in train_props) {
  for (i in 1:reps) {
    
    # Estratificación del conjunto de entrenamiento
    idx_train <- createDataPartition(datos_modelo$DengueFactor, p = p, list = FALSE)
    datos_train <- datos_modelo[idx_train, ]
    datos_test <- datos_modelo[-idx_train, ]
    
    # Balancear clases en el conjunto de entrenamiento con upSample()
    datos_train_balanceado <- upSample(
      x = datos_train[, c("Age_woe", "Platelet Count_woe")],
      y = datos_train$DengueFactor,
      yname = "DengueFactor"
    )
    
    # Entrenar modelo logístico
    modelo <- train(
      DengueFactor ~ Age_woe + `Platelet Count_woe`,
      data = datos_train_balanceado,
      method = "glm",
      trControl = ctrl,
      metric = "ROC"
    )
    
    # Predicción sobre conjunto de prueba (no balanceado)
    pred_test <- predict(modelo, newdata = datos_test, type = "prob")
    
    # Calcular AUC
    auc_test <- roc(response = datos_test$DengueFactor,
                    predictor = pred_test$Sí,
                    levels = c("No", "Sí"))$auc

    # Guardar resultados
    resultados_balanceados <- rbind(resultados_balanceados,
                        data.frame(TamanoEntrenamiento = round(p * 100),
                                   Repeticion = i,
                                   AUC_Test = auc_test))
  }
}


```

```{r}
# Mostrar tablas resultados
print(resultados_balanceados)
resumen_balanceados <- aggregate(AUC_Test ~ TamanoEntrenamiento, data = resultados_balanceados, FUN = mean)
print(resumen_balanceados)
```

El balanceo artificial mediante sobremuestreo no mejora significativamente el desempeño del modelo. En algunos casos incluso reduce ligeramente el AUC. Esto se debe a que las variables transformadas (Age_woe y Platelet Count_woe) ya ajustan tan bien al modelo que los cambios en el tamaño de entrenamiento o el balanceo no generan diferencias sustanciales en la capacidad predictiva.

Considerar que: El sobremuestreo (overfitting) puede hacer que algunas observaciones se repitan mucho.

# Validación cruzada repetida (30% de trainig)

```{r, warning=FALSE, message=FALSE}
set.seed(187)

# Variable de clase como factor binario
datos_modelo$DengueFactor <- factor(
  ifelse(datos_modelo$`Dengue Diagnosis` == 1, "Sí", "No"),
  levels = c("No", "Sí")
)

# Repeticiones de la validación
reps <- 100
porcentaje_entrenamiento <- 0.3

# Almacenar resultados
metricas <- data.frame()

for (i in 1:reps) {
  
  #Partición estratificada (30% para training)
  idx_train <- createDataPartition(datos_modelo$DengueFactor, p = porcentaje_entrenamiento, list = FALSE)
  train_data <- datos_modelo[idx_train, ]
  test_data <- datos_modelo[-idx_train, ]
  
  #Control de validación cruzada estratificada
  ctrl <- trainControl(
    method = "cv",
    number = 5,
    classProbs = TRUE,
    summaryFunction = twoClassSummary,
    savePredictions = "final"
  )
  
  # Ajuste de modelo
  modelo <- train(
    DengueFactor ~ Age_woe + `Platelet Count_woe`,
    data = train_data,
    method = "glm",
    metric = "ROC",
    trControl = ctrl
  )
  
  #Predicción sobre test externo
  pred_probs <- predict(modelo, newdata = test_data, type = "prob")
  pred_clase <- predict(modelo, newdata = test_data)
  
  #AUC
  auc <- roc(response = test_data$DengueFactor,
             predictor = pred_probs$Sí,
             levels = c("No", "Sí"))$auc
  
  #Matriz de confusión y métricas
  cm <- confusionMatrix(pred_clase, test_data$DengueFactor, positive = "Sí")
  
  metricas <- rbind(metricas, data.frame(
    Repeticion = i,
    AUC = auc,
    Accuracy = cm$overall["Accuracy"],
    Sensibilidad = cm$byClass["Sensitivity"],
    Especificidad = cm$byClass["Specificity"],
    F1 = cm$byClass["F1"],
    Precision = cm$byClass["Precision"]
  ))
}

# Ver resumen
print(summary(metricas))

```

El modelo logístico validado con 100 repeticiones usando solo el 30% de los datos para entrenamiento mantiene un rendimiento sobresaliente. Se obtuvo un AUC promedio de 0.9929, con exactitud media del 98.96%, sensibilidad del 99.51% y especificidad del 97.80%.

Este desempeño se debe a que las variables transformadas Age_woe y Platelet Count_woe reflejan de forma muy clara el diagnóstico de dengue. Más que mejorar el modelo, los cambios en técnicas de muestreo o balanceo tienen poco efecto, porque estas variables ya capturan de manera directa y efectiva la señal del fenómeno.
